"""
Script d'Entra√Ænement avec 1000 Images
Temps estim√© : 30-50 minutes pour les 3 mod√®les
"""

import sys
import os

# Ajouter le r√©pertoire parent au path
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

import numpy as np
from preprocessing.data_loader import RDD2022DataLoader
from preprocessing.preprocessing import ImagePreprocessor
from models.unet_scratch import create_unet_model
from models.hybrid_model import create_hybrid_model
from models.model_utils import DiceCoefficient, IoUMetric
from training.callbacks import create_callbacks
from utils.config import *
from utils.helpers import set_seeds

import tensorflow as tf


# =============================================================================
# CONFIGURATION GLOBALE
# =============================================================================
NUM_TRAIN_IMAGES = 1000  # ‚Üê CHANGE ICI pour modifier le nombre d'images train
NUM_VAL_IMAGES = 200     # ‚Üê CHANGE ICI pour modifier le nombre d'images val
NUM_EPOCHS = 10          # ‚Üê CHANGE ICI pour modifier le nombre d'epochs


def train_unet_100(data_path, epochs=NUM_EPOCHS):
    """
    Entra√Æne U-Net sur 1000 images
    Temps estim√© : 10-15 minutes
    """
    print("\n" + "=" * 100)
    print(f"‚ö° ENTRA√éNEMENT U-NET - {NUM_TRAIN_IMAGES} IMAGES, {epochs} EPOCHS")
    print("=" * 100)
    print(f"‚è±Ô∏è  Temps estim√© : 10-15 minutes")
    print("=" * 100)
    
    # Configuration
    set_seeds(RANDOM_SEED)
    
    # 1. Charger les donn√©es
    print(f"\nüì¶ Chargement de {NUM_TRAIN_IMAGES} images...")
    
    train_loader = RDD2022DataLoader(data_path, split='train')
    val_loader = RDD2022DataLoader(data_path, split='val')
    
    # Charger les images
    preprocessor = ImagePreprocessor(target_size=IMG_SIZE, normalize=True)
    
    train_images = []
    train_masks = []
    for i in range(NUM_TRAIN_IMAGES):
        img, mask, _ = train_loader[i]
        train_images.append(img)
        train_masks.append(mask)
    
    val_images = []
    val_masks = []
    for i in range(NUM_VAL_IMAGES):
        img, mask, _ = val_loader[i]
        val_images.append(img)
        val_masks.append(mask)
    
    # Pr√©traiter
    print("üîß Pr√©traitement...")
    X_train, y_train = preprocessor.preprocess_batch(train_images, train_masks)
    X_val, y_val = preprocessor.preprocess_batch(val_images, val_masks)
    
    # Convertir en categorical
    y_train_cat = np.array([preprocessor.mask_to_categorical(m) for m in y_train])
    y_val_cat = np.array([preprocessor.mask_to_categorical(m) for m in y_val])
    
    print(f"‚úÖ Train: {X_train.shape[0]} images")
    print(f"‚úÖ Val: {X_val.shape[0]} images")
    
    # 2. Cr√©er le mod√®le
    print("\nüèóÔ∏è  Cr√©ation du mod√®le U-Net...")
    
    model = create_unet_model(
        input_shape=IMG_SIZE + (IMG_CHANNELS,),
        num_classes=NUM_CLASSES + 1,
        filters_base=64,
        compile_model=True
    )
    
    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy', DiceCoefficient(), IoUMetric()]
    )
    
    print("‚úÖ Mod√®le cr√©√©")
    
    # 3. Callbacks
    callbacks = create_callbacks(
        model_name='unet_1000img',
        models_dir=MODELS_DIR,
        log_dir=LOGS_DIR,
        monitor='val_dice_coefficient',
        patience_early_stop=5,  # R√©duit pour 100 images
        patience_reduce_lr=3
    )
    
    # 4. Entra√Ænement
    print(f"\nüöÄ Entra√Ænement ({epochs} epochs)...\n")
    
    history = model.fit(
        X_train, y_train_cat,
        validation_data=(X_val, y_val_cat),
        epochs=epochs,
        batch_size=8,  # R√©duit pour aller plus vite avec peu d'images
        callbacks=callbacks,
        verbose=1
    )
    
    # 5. R√©sultats
    print("\n" + "=" * 100)
    print(f"‚úÖ U-NET TERMIN√â ({NUM_TRAIN_IMAGES} images, {epochs} epochs)")
    print("=" * 100)
    
    final_metrics = {
        'train_dice': history.history['dice_coefficient'][-1],
        'train_iou': history.history['iou'][-1],
        'val_dice': history.history['val_dice_coefficient'][-1],
        'val_iou': history.history['val_iou'][-1]
    }
    
    print(f"\nüìä R√©sultats finaux:")
    for key, value in final_metrics.items():
        print(f"  - {key}: {value:.4f}")
    
    return model, history


def train_hybrid_100(data_path, epochs=NUM_EPOCHS):
    """
    Entra√Æne le mod√®le Hybride sur 1000 images
    Temps estim√© : 15-20 minutes
    """
    print("\n" + "=" * 100)
    print(f"‚ö° ENTRA√éNEMENT HYBRIDE - {NUM_TRAIN_IMAGES} IMAGES, {epochs} EPOCHS")
    print("=" * 100)
    print(f"‚è±Ô∏è  Temps estim√© : 15-20 minutes")
    print("=" * 100)
    
    # Configuration
    set_seeds(RANDOM_SEED)
    
    # 1. Charger les donn√©es
    print(f"\nüì¶ Chargement de {NUM_TRAIN_IMAGES} images...")
    
    train_loader = RDD2022DataLoader(data_path, split='train')
    val_loader = RDD2022DataLoader(data_path, split='val')
    
    # Charger et pr√©traiter
    preprocessor = ImagePreprocessor(target_size=IMG_SIZE, normalize=True)
    
    train_images = []
    train_masks = []
    for i in range(NUM_TRAIN_IMAGES):
        img, mask, _ = train_loader[i]
        train_images.append(img)
        train_masks.append(mask)
    
    val_images = []
    val_masks = []
    for i in range(NUM_VAL_IMAGES):
        img, mask, _ = val_loader[i]
        val_images.append(img)
        val_masks.append(mask)
    
    print("üîß Pr√©traitement...")
    X_train, y_train = preprocessor.preprocess_batch(train_images, train_masks)
    X_val, y_val = preprocessor.preprocess_batch(val_images, val_masks)
    
    y_train_cat = np.array([preprocessor.mask_to_categorical(m) for m in y_train])
    y_val_cat = np.array([preprocessor.mask_to_categorical(m) for m in y_val])
    
    print(f"‚úÖ Train: {X_train.shape[0]} images")
    print(f"‚úÖ Val: {X_val.shape[0]} images")
    
    # 2. Cr√©er le mod√®le
    print("\nüèóÔ∏è  Cr√©ation du mod√®le Hybride...")
    
    model = create_hybrid_model(
        input_shape=IMG_SIZE + (IMG_CHANNELS,),
        num_classes=NUM_CLASSES + 1,
        filters_base=64,
        compile_model=True
    )
    
    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy', DiceCoefficient(), IoUMetric()]
    )
    
    print("‚úÖ Mod√®le cr√©√©")
    
    # 3. Callbacks
    callbacks = create_callbacks(
        model_name='hybrid_1000img',
        save_dir=MODELS_DIR,
        logs_dir=LOGS_DIR,
        monitor='val_dice_coefficient',
        patience_early=5,
        patience_lr=3
    )
    
    # 4. Entra√Ænement
    print(f"\nüöÄ Entra√Ænement ({epochs} epochs)...\n")
    
    history = model.fit(
        X_train, y_train_cat,
        validation_data=(X_val, y_val_cat),
        epochs=epochs,
        batch_size=8,
        callbacks=callbacks,
        verbose=1
    )
    
    # 5. R√©sultats
    print("\n" + "=" * 100)
    print(f"‚úÖ HYBRIDE TERMIN√â ({NUM_TRAIN_IMAGES} images, {epochs} epochs)")
    print("=" * 100)
    
    final_metrics = {
        'train_dice': history.history['dice_coefficient'][-1],
        'train_iou': history.history['iou'][-1],
        'val_dice': history.history['val_dice_coefficient'][-1],
        'val_iou': history.history['val_iou'][-1]
    }
    
    print(f"\nüìä R√©sultats finaux:")
    for key, value in final_metrics.items():
        print(f"  - {key}: {value:.4f}")
    
    return model, history


def train_yolo_100(data_path, epochs=NUM_EPOCHS, use_segmentation=False):
    """
    Entra√Æne YOLO sur 1000 images
    Temps estim√© : 10-15 minutes

    Args:
        data_path: Chemin vers le dataset
        epochs: Nombre d'epochs
        use_segmentation: Si True, utilise le mod√®le de segmentation (n√©cessite des labels polygones).
                          Si False (d√©faut), utilise le mod√®le de d√©tection (labels bounding box).

    Note:
        - Pour la segmentation (use_segmentation=True), les labels doivent √™tre au format:
          class x1 y1 x2 y2 x3 y3 ... (coordonn√©es polygones normalis√©es)
        - Pour la d√©tection (use_segmentation=False), les labels doivent √™tre au format:
          class x_center y_center width height (coordonn√©es bbox normalis√©es)
    """
    mode = "SEGMENTATION" if use_segmentation else "D√âTECTION"
    model_file = 'yolov8n-seg.pt' if use_segmentation else 'yolov8n.pt'

    print("\n" + "=" * 100)
    print(f"‚ö° ENTRA√éNEMENT YOLO {mode} - {NUM_TRAIN_IMAGES} IMAGES, {epochs} EPOCHS")
    print("=" * 100)
    print(f"‚è±Ô∏è  Temps estim√© : 10-15 minutes")
    print(f"üì¶ Mod√®le: {model_file}")
    print("=" * 100)

    try:
        from ultralytics import YOLO
        from models.yolo_pretrained import create_yolo_data_yaml
        import shutil
        from pathlib import Path

        # Cr√©er un dataset temporaire avec 100 images
        print(f"\nüì¶ Cr√©ation dataset temporaire ({NUM_TRAIN_IMAGES} images)...")

        temp_dir = Path(data_path).parent / 'RDD_SPLIT_1000'

        # Supprimer l'ancien si existe
        if temp_dir.exists():
            shutil.rmtree(temp_dir)

        # Cr√©er la structure
        (temp_dir / 'train' / 'images').mkdir(parents=True, exist_ok=True)
        (temp_dir / 'train' / 'labels').mkdir(parents=True, exist_ok=True)
        (temp_dir / 'val' / 'images').mkdir(parents=True, exist_ok=True)
        (temp_dir / 'val' / 'labels').mkdir(parents=True, exist_ok=True)

        # Copier 100 images train
        source_train_img = Path(data_path) / 'train' / 'images'
        source_train_lbl = Path(data_path) / 'train' / 'labels'

        train_files = list(source_train_img.glob('*.jpg'))[:NUM_TRAIN_IMAGES]

        for img_file in train_files:
            shutil.copy(img_file, temp_dir / 'train' / 'images')
            lbl_file = source_train_lbl / (img_file.stem + '.txt')
            if lbl_file.exists():
                shutil.copy(lbl_file, temp_dir / 'train' / 'labels')

        # Copier 20 images val
        source_val_img = Path(data_path) / 'val' / 'images'
        source_val_lbl = Path(data_path) / 'val' / 'labels'

        val_files = list(source_val_img.glob('*.jpg'))[:NUM_VAL_IMAGES]

        for img_file in val_files:
            shutil.copy(img_file, temp_dir / 'val' / 'images')
            lbl_file = source_val_lbl / (img_file.stem + '.txt')
            if lbl_file.exists():
                shutil.copy(lbl_file, temp_dir / 'val' / 'labels')

        print(f"‚úÖ Dataset cr√©√©: {temp_dir}")

        # Cr√©er le fichier YAML
        yaml_path = temp_dir / 'data.yaml'
        create_yolo_data_yaml(
            train_path=str(temp_dir / 'train'),
            val_path=str(temp_dir / 'val'),
            output_path=str(yaml_path)
        )

        # Cr√©er le mod√®le YOLO (d√©tection ou segmentation)
        print(f"\nüèóÔ∏è  Chargement YOLO ({mode})...")
        yolo = YOLO(model_file)
        print(f"‚úÖ Mod√®le {model_file} charg√©")

        # Entra√Æner
        print(f"\nüöÄ Entra√Ænement YOLO ({epochs} epochs)...\n")

        results = yolo.train(
            data=str(yaml_path),
            epochs=epochs,
            batch=4,  # R√©duit pour aller plus vite
            imgsz=640,
            project=str(Path(data_path).parent / 'yolo_temp_results'),
            name='yolo_1000img',
            patience=5,
            save=False,  # Ne pas sauvegarder pour gagner du temps
            plots=False,
            verbose=True
        )

        print("\n" + "=" * 100)
        print(f"‚úÖ YOLO {mode} TERMIN√â ({NUM_TRAIN_IMAGES} images, {epochs} epochs)")
        print("=" * 100)

        # Nettoyage
        print("\nüóëÔ∏è  Nettoyage...")
        shutil.rmtree(temp_dir)

        return yolo, results

    except ImportError:
        print("‚ùå Ultralytics non disponible!")
        return None, None


if __name__ == "__main__":
    # Chemin vers le dataset
    DATA_PATH = "C:/Users/DELL/Desktop/dataset/RDD_SPLIT"
    
    # V√©rifier que le chemin existe
    if not os.path.exists(DATA_PATH):
        print(f"‚ùå ERREUR: Le dataset n'existe pas √† {DATA_PATH}")
        sys.exit(1)
    
    # Menu
    print("\n" + "=" * 100)
    print(f"‚ö° ENTRA√éNEMENT ULTRA-RAPIDE - {NUM_TRAIN_IMAGES} IMAGES, {NUM_EPOCHS} EPOCHS")
    print("=" * 100)
    print("\nüí° Pour changer le nombre d'images ou d'epochs :")
    print(f"   - Ouvre ce fichier et modifie les lignes 19-21")
    print(f"   - NUM_TRAIN_IMAGES = {NUM_TRAIN_IMAGES}  ‚Üê Nombre d'images train")
    print(f"   - NUM_VAL_IMAGES = {NUM_VAL_IMAGES}      ‚Üê Nombre d'images val")
    print(f"   - NUM_EPOCHS = {NUM_EPOCHS}            ‚Üê Nombre d'epochs")
    print()
    print("Quel mod√®le voulez-vous entra√Æner ?")
    print("  1. U-Net (~10-15 min)")
    print("  2. Hybride (~15-20 min)")
    print("  3. YOLO D√©tection (~10-15 min) - pour labels bounding box")
    print("  4. TOUS (~35-50 min)")
    print()
    
    choice = input("Votre choix (1-4): ").strip()
    
    if choice == '1':
        model, history = train_unet_100(DATA_PATH)
        
    elif choice == '2':
        model, history = train_hybrid_100(DATA_PATH)
        
    elif choice == '3':
        model, results = train_yolo_100(DATA_PATH)
        
    elif choice == '4':
        print("\nüöÄ Entra√Ænement des 3 mod√®les...")
        print(f"‚è±Ô∏è  Temps total estim√© : ~35-50 minutes")
        print()
        
        # U-Net
        print("\n" + "üîπ" * 50)
        print("1/3 - U-NET")
        print("üîπ" * 50)
        unet_model, unet_history = train_unet_100(DATA_PATH)
        
        # Hybride
        print("\n" + "üîπ" * 50)
        print("2/3 - HYBRIDE")
        print("üîπ" * 50)
        hybrid_model, hybrid_history = train_hybrid_100(DATA_PATH)
        
        # YOLO
        print("\n" + "üîπ" * 50)
        print("3/3 - YOLO")
        print("üîπ" * 50)
        yolo_model, yolo_results = train_yolo_100(DATA_PATH)
        
        print("\n" + "=" * 100)
        print("üéâ TOUS LES ENTRA√éNEMENTS TERMIN√âS!")
        print("=" * 100)
        print(f"\nüìä R√©sum√©:")
        print(f"  - {NUM_TRAIN_IMAGES} images d'entra√Ænement")
        print(f"  - {NUM_EPOCHS} epochs par mod√®le")
        print(f"  - 3 mod√®les entra√Æn√©s avec succ√®s")
        
    else:
        print("‚ùå Choix invalide!")